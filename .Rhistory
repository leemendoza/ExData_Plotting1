WHEN [RUG] = 5.21 THEN 27429
WHEN [RUG] = 5.12 THEN 20011
WHEN [RUG] = 5.11 THEN 12811
WHEN [RUG] = 6.21 THEN 27429
WHEN [RUG] = 6.12 THEN 20011
WHEN [RUG] = 6.11 THEN 12811
WHEN [RUG] = 7.41 THEN 32904
WHEN [RUG] = 7.31 THEN 27429
WHEN [RUG] = 7.21 THEN 22916
WHEN [RUG] = 7.12 THEN 19237
WHEN [RUG] = 7.11 THEN 10244
ELSE 0
END
,[A_1]	AS [ARD]
,[A_2] AS [INIT]
,[AA_1_a] AS [FNAME]
,[AA_1_b] AS [LNAME]
,[AA_1_c] AS [MI]
,[AA_3_a] AS [SSN]
FROM [TSData].[dbo].[IR_MDSHC_A]
WHERE Deleted = 0
AND RUG IS NOT NULL
AND [A_1] >= DATEADD(year, -3, GETDATE()) AND [AA_3_a] IS NOT NULL
AND [AA_3_a] != \'\'
ORDER BY [AA_3_a], [A_1] DESC", sep = "")
## get connection
telesyshandle <- odbcDriverConnect('driver={SQL Server};server=BHSF-BTR-W324; database=TSData; Uid=mdshcuser; Pwd=test;')
## get data set
system.time(mdshcs <- sqlQuery(telesyshandle, mdshcSearchStr))
## close the database connection
close(telesyshandle)
## close connection
source('C:/GitHub/HomeCode/wellsSample.R')
library(RODBC)
library(data.table)
############################################
## date collected = 2014-10-22
############################################
## Start the clock!
ptm <- proc.time()
## the insert dashes function - takes a string and inserts dashes to format as SSN
insertDashes <- function(ssn)
{ dashedSsn <- paste(c(substr(ssn, 1, 3), substr(ssn, 4, 5), substr(ssn, 6, 9)), collapse="-")
return(dashedSsn)
}
## open a connection to the LOCS database
pochandle <- odbcDriverConnect('driver={SQL Server};server=BHSF-BTR-W453;database=LOCS;uid=dbuLOCS;pwd=dbulocs')
## get all plans of care expiring after today.
pocSearchStr = paste("SELECT Requestor.LastName + \', \' + Requestor.FirstName AS 'Client' ,
Requestor.SSN ,
lstParish.Region ,
UserDet.LastName + ', ' + UserDet.FirstName AS 'Assessor' ,
ProvName ,
Assessment.CertEndDate
FROM   Requestor
INNER JOIN Program ON Requestor.RequestorKey = Program.RequestorKey
INNER JOIN Assessment ON Assessment.ProgramKey = Program.ProgramKey
INNER JOIN ( SELECT  *
FROM  AssessmentPOC poc
WHERE poc.AssessmentPOCKey = ( SELECT TOP 1
poc1.AssessmentPOCKey
FROM       AssessmentPOC poc1
WHERE       poc.AssessmentKey = poc1.AssessmentKey
AND poc1.DeleteKey = 0
ORDER BY poc1.POCCompletedDate DESC
)
) poc ON poc.AssessmentKey = Assessment.AssessmentKey
INNER JOIN ( SELECT  *
FROM  PriorAuthSRI pa
WHERE pa.PriorAuthSRIKey = ( SELECT TOP 1
pa1.PriorAuthSRIKey
FROM              PriorAuthSRI pa1
WHERE       pa1.AssessmentKey = pa.AssessmentKey
AND pa1.DeleteKey = 0
ORDER BY       pa1.CPOCEndDate DESC
)
) pa ON Assessment.AssessmentKey = pa.AssessmentKey
INNER JOIN lstParish ON Requestor.phyParish = lstParish.Pcode
INNER JOIN RefTable AS b ON Assessment.AssessmentStatus = b.RefKey
INNER JOIN RefTable AS c ON Assessment.AssessmentType = c.RefKey
INNER JOIN UserDet ON poc.MDSCompletedBy = UserDet.UserID
INNER JOIN Provider ON pa.Provno = Provider.ProviderNo
WHERE
CertEndDate >= GETDATE()
AND b.ShortDescription = \'APPROVED\'
AND ( c.ShortDescription = \'re-assessment\'
OR c.ShortDescription = \'initial assessment\'
)
AND poc.DeleteKey = 0
AND Assessment.DeleteKey = 0
AND Requestor.DeleteKey = 0
AND Program.DeleteKey = 0
ORDER BY SSN", sep = "")
system.time(poc <- sqlQuery(pochandle, pocSearchStr))
close(pochandle)
## open a connection to the OPTS database
repshandle <- odbcDriverConnect('driver={SQL Server};server=BHSF-BTR-W359;database=ParticipantServices;uid=dbuOPTSReadOnly;pwd=dbuoptsro')
## representatives and their clients
repsSearchStr = "SELECT   LTRIM(RTRIM(a.nameLast + \', \' + a.nameFirst)) AS [REP]
, a.[address] AS [RepAddress]
, LTRIM(RTRIM(t_Person.nameLast + \', \' + t_Person.nameFirst)) AS [Client]
, REPLACE(t_Person.SSN, \'-\', '') AS SSN
FROM    t_Contacts a INNER JOIN
t_Person ON a.perID = t_Person.perID
WHERE a.legalAuthorityTypeID = 4
AND a.nameLast != \'\'
AND a.nameFirst != \'\'
AND SSN IS NOT NULL
AND SSN != \'\'
ORDER BY SSN"
system.time(reps <- sqlQuery(repshandle, repsSearchStr))
## close the database connection
close(repshandle)
## convert to data tables for joining
poc_dt = data.table(poc)
setkey(poc_dt, SSN)
reps_dt = data.table(reps)
setkey(reps_dt, SSN)
## join them
poc_reps = merge(x = reps_dt, y = poc_dt, by = "SSN", all.x = all)
## sort the poc_reps records
poc_reps = poc_reps[with(poc_reps, order(REP, Client.x)), ]
poc_dt = poc_dt[with(poc_dt, order(Client)), ]
write.csv(poc_reps, "c:\\data\\poc_reps.csv")
## Stop the clock and report the time elapsed
proc.time() - ptm
poc_reps = merge(x = reps_dt, y = poc_dt, by = "SSN", all.x = TRUE)
View(poc_dt)
View(reps_dt)
poc_reps = merge(x = reps_dt, y = poc_dt, by = "SSN")
View(poc_reps)
recs = poc_reps[poc_reps$Client.x == "Adams, Barbara",]
rm(list = ls())
library(dplyr)
library(reshape2)
# link to source data in zip file
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
## Function for downloading the dataset from the web
get_data <- function(source_url = url) {
## check to see if the directory exists already or create one
if (!file.exists("./data/dataset.zip")) {
dir.create("./data")
print("Created dir for data.")
}
#print(list.files("."))
## check to see if the zip file exists already or download it
if (!file.exists("./data/dataset.zip")) {
download.file(url = url, destfile = "./data/dataset.zip", method = "auto")
dateDownloaded <- date()
print(c("==== Downloaded data on:  ",dateDownloaded))
}
#print(list.files("./data"))
####################################################################
## STEP 1 - Merges the training and the test sets to create one data set.
##
## extract and read the subject data from the zip file
con_subject_train <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/train/subject_train.txt")
subject_train <- read.table(con_subject_train)
#print(str(subject_train))
#close(con_subject_train)
con_subject_test <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/test/subject_test.txt")
subject_test <- read.table(con_subject_test)
#print(str(subject_test))
#close(con_subject_test)
subject_combined <- rbind(subject_train, subject_test)
#print(str(subject_combined))
# add names to the subject table
names(subject_combined) <- "subject_id"
## extract or read the activity data needed from the zip file
con_activity_train <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/train/y_train.txt")
activity_train <- read.table(con_activity_train)
#print(str(activity_train))
#close(con_activity_train)
con_activity_test <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/test/y_test.txt")
activity_test <- read.table(con_activity_test)
#print(str(activity_test))
#close(con_activity_test)
activity_combined <- rbind(activity_train, activity_test)
#print(str(activity_combined))
# add names to the activity table
names(activity_combined) <- "activity"
#   print("==========  activity_combined  ===================================== ")
#   print(str(activity_combined))
## extract or read the measurements data needed from the zip file
con_measure_train <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/train/X_train.txt")
measure_train <- read.table(con_measure_train)
#print(str(measure_train))
#close(con_measure_train)
con_measure_test <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/test/X_test.txt")
measure_test <- read.table(con_measure_test)
#print(str(measure_test))
#close(con_measure_test)
measure_combined <- rbind(measure_train, measure_test)
con_feat <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/features.txt")
feat <- read.table(con_feat)
#print(str(feat))
#close(con_feat)
# add names to the feat table
names(feat) <- c("measure_num","measure_name")
####################################################################
## STEP 2. Extracts only the measurements on the mean and standard deviation for each measurement.
##
####################################################################
## STEP 2. Extracts only the measurements on the mean and standard deviation for each measurement.
##
#feat_keep <- feat[,feat$measure_num < 4 ]
#   feat_tbl <- tbl_df(feat)
#   filter(feat_tbl, measure_name %in% c("mean", "std") )
#  print("feat_tbl ================ ")
#  print(str(feat_tbl))
mnames <- feat$measure_name
keep_names <- mnames %in% grep("mean|std",mnames, value = TRUE)
#  print("===  keep_names ================ ")
#  print(str(keep_names))
# print(sum(keep_names))
#dtbl <- tbl_df(dframe)
# print("===  dtbl ================ ")
# print(str(dtbl))
#
# print("===  measure nums to keep ================ ")
# print(feat$measure_num[keep_names])
measure_dtbl <- tbl_df(measure_combined)
dtbl_small <- select(measure_dtbl, feat$measure_num[keep_names]) # select columns by position
# print("===  dtbl_small ================ ")
# print(str(dtbl_small))
dframe <- cbind(subject_combined, activity_combined, dtbl_small)
# print("data frame ================ ")
# print(str(dframe))
####################################################################
## STEP 3 Goal: Use descriptive activity names to name the activities in the data set
##
## extract or read the activity labels needed from the zip file
con_al <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/activity_labels.txt")
al <- read.table(con_al)
# add names to the activity table
names(al) <- c("activity_id","activity_label")
#print(str(al))
#close(con_al)
# Now replace the activity codes (integers  1 to 6) with the text labels from the file activity_labels.txt
dframe$activity <-  al[dframe$activity, 2]
####################################################################
## STEP 4 Goal: Appropriately label the data set with descriptive variable names.
##
## remove unhelpful parts of feature names using  make.names(names, unique = FALSE, allow_ = TRUE)
clean_names <- make.names(feat$measure_name[keep_names], unique = TRUE)
cleaner_names <- gsub('\\.+','',clean_names)  # take out the dots put in by make.names()
## replace the variable names on the data frame with the clean ones
names(dframe) <- c("subject_id","activity", cleaner_names)
#print(names(dframe))
####################################################################
## STEP 5 From the data set in step 4, creates a second, independent tidy data set
#     with the average of each variable for each activity and each subject.
#
# Example
## reshape2  does its thing:
# library(reshape2)
# melted <- melt(data, id.vars=c("sex", "treatment"))
## This part is new:
# library(dplyr)
# grouped <- group_by(melted, sex, treatment)
# summarise(grouped, mean=mean(value), sd=sd(value))
dframe_melted <- melt(dframe, id.vars=c("activity", "subject_id"))
dframe_grouped <-
dframe_melted %>% group_by(activity, subject_id) %>%
summarise(mean=mean(value))
# dframe_grouped <- group_by(dframe_melted, activity, subject_id)
#                   summarize(dframe_grouped,mean=mean(value))
# print("data frame grouped  ================ ")
print(dframe_grouped)
print(dim(dframe_grouped))
write.table(dframe_grouped, file = "activity_subject_summary.txt", row.name=FALSE)
}
getwd()
library(dplyr)
library(reshape2)
# link to source data in zip file
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
## Function for downloading the dataset from the web
get_data <- function(source_url = url) {
## check to see if the directory exists already or create one
if (!file.exists("./data/dataset.zip")) {
dir.create("./data")
print("Created dir for data.")
}
#print(list.files("."))
## check to see if the zip file exists already or download it
if (!file.exists("./data/dataset.zip")) {
download.file(url = url, destfile = "./data/dataset.zip", method = "auto")
dateDownloaded <- date()
print(c("==== Downloaded data on:  ",dateDownloaded))
}
#print(list.files("./data"))
####################################################################
## STEP 1 - Merges the training and the test sets to create one data set.
##
## extract and read the subject data from the zip file
con_subject_train <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/train/subject_train.txt")
subject_train <- read.table(con_subject_train)
#print(str(subject_train))
#close(con_subject_train)
con_subject_test <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/test/subject_test.txt")
subject_test <- read.table(con_subject_test)
#print(str(subject_test))
#close(con_subject_test)
subject_combined <- rbind(subject_train, subject_test)
#print(str(subject_combined))
# add names to the subject table
names(subject_combined) <- "subject_id"
## extract or read the activity data needed from the zip file
con_activity_train <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/train/y_train.txt")
activity_train <- read.table(con_activity_train)
#print(str(activity_train))
#close(con_activity_train)
con_activity_test <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/test/y_test.txt")
activity_test <- read.table(con_activity_test)
#print(str(activity_test))
#close(con_activity_test)
activity_combined <- rbind(activity_train, activity_test)
#print(str(activity_combined))
# add names to the activity table
names(activity_combined) <- "activity"
#   print("==========  activity_combined  ===================================== ")
#   print(str(activity_combined))
## extract or read the measurements data needed from the zip file
con_measure_train <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/train/X_train.txt")
measure_train <- read.table(con_measure_train)
#print(str(measure_train))
#close(con_measure_train)
con_measure_test <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/test/X_test.txt")
measure_test <- read.table(con_measure_test)
#print(str(measure_test))
#close(con_measure_test)
measure_combined <- rbind(measure_train, measure_test)
con_feat <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/features.txt")
feat <- read.table(con_feat)
#print(str(feat))
#close(con_feat)
# add names to the feat table
names(feat) <- c("measure_num","measure_name")
####################################################################
## STEP 2. Extracts only the measurements on the mean and standard deviation for each measurement.
##
#feat_keep <- feat[,feat$measure_num < 4 ]
#   feat_tbl <- tbl_df(feat)
#   filter(feat_tbl, measure_name %in% c("mean", "std") )
#  print("feat_tbl ================ ")
#  print(str(feat_tbl))
mnames <- feat$measure_name
keep_names <- mnames %in% grep("mean|std",mnames, value = TRUE)
#  print("===  keep_names ================ ")
#  print(str(keep_names))
# print(sum(keep_names))
#dtbl <- tbl_df(dframe)
# print("===  dtbl ================ ")
# print(str(dtbl))
#
# print("===  measure nums to keep ================ ")
# print(feat$measure_num[keep_names])
measure_dtbl <- tbl_df(measure_combined)
dtbl_small <- select(measure_dtbl, feat$measure_num[keep_names]) # select columns by position
# print("===  dtbl_small ================ ")
# print(str(dtbl_small))
dframe <- cbind(subject_combined, activity_combined, dtbl_small)
# print("data frame ================ ")
# print(str(dframe))
####################################################################
## STEP 3 Goal: Use descriptive activity names to name the activities in the data set
##
## extract or read the activity labels needed from the zip file
con_al <- unz(description="./data/dataset.zip", filename="UCI HAR Dataset/activity_labels.txt")
al <- read.table(con_al)
# add names to the activity table
names(al) <- c("activity_id","activity_label")
#print(str(al))
#close(con_al)
# Now replace the activity codes (integers  1 to 6) with the text labels from the file activity_labels.txt
dframe$activity <-  al[dframe$activity, 2]
####################################################################
## STEP 4 Goal: Appropriately label the data set with descriptive variable names.
##
## remove unhelpful parts of feature names using  make.names(names, unique = FALSE, allow_ = TRUE)
clean_names <- make.names(feat$measure_name[keep_names], unique = TRUE)
cleaner_names <- gsub('\\.+','',clean_names)  # take out the dots put in by make.names()
## replace the variable names on the data frame with the clean ones
names(dframe) <- c("subject_id","activity", cleaner_names)
#print(names(dframe))
####################################################################
## STEP 5 From the data set in step 4, creates a second, independent tidy data set
#     with the average of each variable for each activity and each subject.
#
# Example
## reshape2  does its thing:
# library(reshape2)
# melted <- melt(data, id.vars=c("sex", "treatment"))
## This part is new:
# library(dplyr)
# grouped <- group_by(melted, sex, treatment)
# summarise(grouped, mean=mean(value), sd=sd(value))
dframe_melted <- melt(dframe, id.vars=c("activity", "subject_id"))
dframe_grouped <-
dframe_melted %>% group_by(activity, subject_id) %>%
summarise(mean=mean(value))
# dframe_grouped <- group_by(dframe_melted, activity, subject_id)
#                   summarize(dframe_grouped,mean=mean(value))
# print("data frame grouped  ================ ")
print(dframe_grouped)
print(dim(dframe_grouped))
write.table(dframe_grouped, file = "activity_subject_summary.txt", row.name=FALSE)
}
get_data()
###############################################
# Exploratory data analysis
# Course project #1
# dataset comes from https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip
# and unzipped to c:\data
# The variables in the dataset are
# Date: Date in format dd/mm/yyyy
# Time: time in format hh:mm:ss
# Global_active_power: household global minute-averaged active power (in kilowatt)
# Global_reactive_power: household global minute-averaged reactive power (in kilowatt)
# Voltage: minute-averaged voltage (in volt)
# Global_intensity: household global minute-averaged current intensity (in ampere)
# Sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy).
#   It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave
#   (hot plates are not electric but gas powered).
# Sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy).
#   It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.
# Sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy).
#   It corresponds to an electric water-heater and an air-conditioner.
## read the data
# Note that in this dataset missing values are coded as ?.
power_data = read.csv("c:\\data\\household_power_consumption.txt", sep=";", na.strings = "?")
# We will only be using data from the dates 2007-02-01 and 2007-02-02.
power_data = power_data[which(power_data$Date == "1/2/2007" | power_data$Date == "2/2/2007"), ]
# concatenate the date and time strings and convert to a time structure...
DateTime = strptime(paste(power_data$Date, power_data$Time, sep = " "), format = "%d/%m/%Y %H:%M:%S")
# add the new column to the dataset
power_data = cbind(DateTime, power_data)
#get rid of useless columns
power_data$Date = NULL
power_data$Time = NULL
# redirect graphic output to a file
png("plot1.png")
#################################### plotting code follows #################################
hist(power_data$Global_active_power, main = "Global Active Power",
xlab = "Global Active Power (kilowatts)", col = "red", ylim = c(0, 1200))
# turn off redirection
dev.off()
###############################################
# Exploratory data analysis
# Course project #1
# dataset comes from https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip
# and unzipped to c:\data
# The variables in the dataset are
# Date: Date in format dd/mm/yyyy
# Time: time in format hh:mm:ss
# Global_active_power: household global minute-averaged active power (in kilowatt)
# Global_reactive_power: household global minute-averaged reactive power (in kilowatt)
# Voltage: minute-averaged voltage (in volt)
# Global_intensity: household global minute-averaged current intensity (in ampere)
# Sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy).
#   It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave
#   (hot plates are not electric but gas powered).
# Sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy).
#   It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.
# Sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy).
#   It corresponds to an electric water-heater and an air-conditioner.
## read the data
# Note that in this dataset missing values are coded as ?.
power_data = read.csv("c:\\data\\household_power_consumption.txt", sep=";", na.strings = "?")
# We will only be using data from the dates 2007-02-01 and 2007-02-02.
power_data = power_data[which(power_data$Date == "1/2/2007" | power_data$Date == "2/2/2007"), ]
# concatenate the date and time strings and convert to a time structure...
DateTime = strptime(paste(power_data$Date, power_data$Time, sep = " "), format = "%d/%m/%Y %H:%M:%S")
# add the new column to the dataset
power_data = cbind(DateTime, power_data)
#get rid of useless columns
power_data$Date = NULL
power_data$Time = NULL
# redirect graphic output to a file
png("plot1.png")
#################################### plotting code follows #################################
hist(power_data$Global_active_power, main = "Global Active Power",
xlab = "Global Active Power (kilowatts)", col = "red", ylim = c(0, 1200))
# turn off redirection
dev.off()
source('C:/GitHub/ExData_Plotting1/plot1.R')
plot(power_data$DateTime, power_data$Global_active_power)
lines(power_data$DateTime, power_data$Global_active_power)
lines(power_data$DateTime, power_data$Global_active_power)
plot(power_data$DateTime, power_data$Global_active_power, type = "n")
lines(power_data$DateTime, power_data$Global_active_power)
lines(power_data$DateTime, power_data$Global_active_power, ylab = "Global Active Power (kilowatts)", xlab = "")
plot(power_data$DateTime, power_data$Global_active_power, type = "n")
lines(power_data$DateTime, power_data$Global_active_power, ylab = "Global Active Power (kilowatts)", xlab = "")
plot(power_data$DateTime, power_data$Global_active_power, type = "n", ylab = "Global Active Power (kilowatts)", xlab = "")
lines(power_data$DateTime, power_data$Global_active_power)
# redirect graphic output to a file
png("plot2.png")
plot(power_data$DateTime, power_data$Global_active_power, type = "n", ylab = "Global Active Power (kilowatts)", xlab = "")
lines(power_data$DateTime, power_data$Global_active_power)
# turn off redirection
dev.off()
source('C:/GitHub/ExData_Plotting1/plot2.R')
getwd()
setwd("C:/GitHub/ExData_Plotting1")
# redirect graphic output to a file
png("plot2.png")
plot(power_data$DateTime, power_data$Global_active_power, type = "n", ylab = "Global Active Power (kilowatts)", xlab = "")
lines(power_data$DateTime, power_data$Global_active_power)
# turn off redirection
dev.off()
